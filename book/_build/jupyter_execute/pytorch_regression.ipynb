{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QliNPatWGeQF"
   },
   "source": [
    "# Pytorch by example, linear regression\n",
    "This example from the pytorch documentation [here](https://pytorch.org/tutorials/beginner/pytorch_with_examples.html) displays generating random y ad x dat and fitting a multi-layer neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "id": "54gmWH2_GILQ",
    "outputId": "460f97b3-7974-484e-9ad5-428fb776b4e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 2.0747294425964355\n",
      "199 0.03381668031215668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299 0.0010593271581456065\n",
      "399 3.9188704249681905e-05\n",
      "499 1.5537893887085374e-06\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold inputs and outputs\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "# Use the nn package to define our model as a sequence of layers. nn.Sequential\n",
    "# is a Module which contains other Modules, and applies them in sequence to\n",
    "# produce its output. Each Linear Module computes output from input using a\n",
    "# linear function, and holds internal Tensors for its weight and bias.\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, D_out),\n",
    ")\n",
    "\n",
    "# The nn package also contains definitions of popular loss functions; in this\n",
    "# case we will use Mean Squared Error (MSE) as our loss function.\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "learning_rate = 1e-4\n",
    "for t in range(500):\n",
    "    # Forward pass: compute predicted y by passing x to the model. Module objects\n",
    "    # override the __call__ operator so you can call them like functions. When\n",
    "    # doing so you pass a Tensor of input data to the Module and it produces\n",
    "    # a Tensor of output data.\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute and print loss. We pass Tensors containing the predicted and true\n",
    "    # values of y, and the loss function returns a Tensor containing the\n",
    "    # loss.\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    # Zero the gradients before running the backward pass.\n",
    "    model.zero_grad()\n",
    "\n",
    "    # Backward pass: compute gradient of the loss with respect to all the learnable\n",
    "    # parameters of the model. Internally, the parameters of each Module are stored\n",
    "    # in Tensors with requires_grad=True, so this call will compute gradients for\n",
    "    # all learnable parameters in the model.\n",
    "    loss.backward()\n",
    "\n",
    "    # Update the weights using gradient descent. Each parameter is a Tensor, so\n",
    "    # we can access its gradients like we did before.\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param -= learning_rate * param.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qWcVUq9RGxTB"
   },
   "source": [
    "Let's update that example for our setting using the voxel level data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "62iyChkPGwZD"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.linear_model as lm\n",
    "## this sets some style parameters\n",
    "sns.set()\n",
    "\n",
    "## Download in the data if it's not already there\n",
    "! if [ ! -e oasis.csv ]; \\\n",
    "  then wget https://raw.githubusercontent.com/bcaffo/ds4bme_intro/master/data/oasis.csv; \\\n",
    "fi;\n",
    "\n",
    "## Read in the data and display a few rows\n",
    "dat = pd.read_csv(\"oasis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "neIwiOlRTIor"
   },
   "outputs": [],
   "source": [
    "trainFraction = .75\n",
    "\n",
    "sample = np.random.uniform(size = 100) < trainFraction\n",
    "trainingDat = dat[sample]\n",
    "testingDat = dat[~sample]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "-tVT-AsOTPgN",
    "outputId": "1f938b04-48b9-4fa2-8b94-160c233b8a7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([80, 7]),\n",
       " torch.Size([80, 1]),\n",
       " torch.Size([20, 7]),\n",
       " torch.Size([20, 1])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.from_numpy(dat[['PD','T1', 'T2', 'FLAIR_10', 'T1_10', 'T2_10', 'FLAIR_20']].values)\n",
    "y = torch.from_numpy(dat[['FLAIR']].values)\n",
    "\n",
    "##pytorch wants type as float\n",
    "x = x.float()\n",
    "y = y.float()\n",
    "\n",
    "xtraining = x[sample]\n",
    "xtesting = x[~sample]\n",
    "ytraining = y[sample]\n",
    "ytesting = y[~sample]\n",
    "\n",
    "[\n",
    " xtraining.size(),\n",
    " ytraining.size(),\n",
    " xtesting.size(),\n",
    " ytesting.size(),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D2UxGTdkaBdO"
   },
   "outputs": [],
   "source": [
    "## Define the model\n",
    "## Dimension of the hidden layer\n",
    "H = 10\n",
    "\n",
    "## Number of predictors\n",
    "D_in = xtraining.size()[1]\n",
    "D_out = 1\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, D_out),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "id": "lnoPaqh7Rm2M",
    "outputId": "9067a2a4-7d16-4efa-8ee0-8ef8d44db9d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 29.259735107421875\n",
      "199 25.00836944580078\n",
      "299 23.992202758789062\n",
      "399 23.417325973510742\n",
      "499 22.948328018188477\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "learning_rate = 1e-4\n",
    "for t in range(500):\n",
    "    y_pred = model(xtraining)\n",
    "    loss = loss_fn(y_pred, ytraining)\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param -= learning_rate * param.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "eZswhY21bcwK",
    "outputId": "bbefd7ef-cf11-4bd1-9ffc-7e99344e2755"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f10525eef70>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "filenames": {
       "image/png": "/workspaces/ds4bio_book/book/_build/jupyter_execute/pytorch_regression_8_1.png"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## try prediction\n",
    "ytesting_pred = model(xtesting)\n",
    "a = ytesting_pred.detach().numpy()\n",
    "\n",
    "plt.scatter(a[:,0], ytesting[:,0])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "notebook6.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}