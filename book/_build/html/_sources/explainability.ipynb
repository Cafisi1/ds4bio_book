{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ON_UFwUQeI_d"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smart-stats/ds4bio_book/blob/main/book/explainability.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> \n",
        "\n",
        "# Explainability\n",
        "\n",
        "Explainability is an important aspect for building trust in a neural network. If you can't explain why your algorithm performs as it does, then at the very least there is concern for overfitting, or fitting on irrelevant features having and association with the outcome. Below we'll show a very basic version of explainability. Let's redo our convnet example, now on the GPU. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WKNmlykeI_x",
        "outputId": "623c7c51-e35c-4235-93b5-0d2a6c93bb93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://raw.githubusercontent.com/cryptopunksnotdead/punks.attributes/master/original/0-999.csv\n",
            "https://raw.githubusercontent.com/cryptopunksnotdead/punks.attributes/master/original/1000-1999.csv\n",
            "https://raw.githubusercontent.com/cryptopunksnotdead/punks.attributes/master/original/2000-2999.csv\n",
            "https://raw.githubusercontent.com/cryptopunksnotdead/punks.attributes/master/original/3000-3999.csv\n",
            "https://raw.githubusercontent.com/cryptopunksnotdead/punks.attributes/master/original/4000-4999.csv\n",
            "https://raw.githubusercontent.com/cryptopunksnotdead/punks.attributes/master/original/5000-5999.csv\n",
            "https://raw.githubusercontent.com/cryptopunksnotdead/punks.attributes/master/original/6000-6999.csv\n",
            "https://raw.githubusercontent.com/cryptopunksnotdead/punks.attributes/master/original/7000-7999.csv\n",
            "https://raw.githubusercontent.com/cryptopunksnotdead/punks.attributes/master/original/8000-8999.csv\n",
            "https://raw.githubusercontent.com/cryptopunksnotdead/punks.attributes/master/original/9000-9999.csv\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "import PIL\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "\n",
        "imgURL = \"https://raw.githubusercontent.com/larvalabs/cryptopunks/master/punks.png\"\n",
        "urllib.request.urlretrieve(imgURL, \"cryptoPunksAll.jpg\")\n",
        "img = PIL.Image.open(\"cryptoPunksAll.jpg\").convert(\"RGB\")\n",
        "imgArray = np.asarray(img)\n",
        "\n",
        "finalArray = np.empty((10000, 3, 24, 24))\n",
        "for i in range(100):\n",
        "  for j in range(100):\n",
        "    a, b = 24 * i, 24 * (i + 1)  \n",
        "    c, d = 24 * j, 24 * (j + 1) \n",
        "    idx = j + i * (100)\n",
        "    finalArray[idx,0,:,:] = imgArray[a:b,c:d,0]\n",
        "    finalArray[idx,1,:,:] = imgArray[a:b,c:d,1]\n",
        "    finalArray[idx,2,:,:] = imgArray[a:b,c:d,2]\n",
        "\n",
        "baseUrl = \"https://raw.githubusercontent.com/cryptopunksnotdead/punks.attributes/master/original/\"\n",
        "for i in range(0,10000, 1000):\n",
        "  url = baseUrl+str(i)+\"-\"+str(i + 999)+\".csv\"\n",
        "  print(url)\n",
        "  if (i == 0):\n",
        "    dat = pd.read_csv(url)\n",
        "  else :\n",
        "    dat = pd.concat ([dat, pd.read_csv(url)], \n",
        "                      join = 'inner',\n",
        "                     ignore_index = True)\n",
        "    \n",
        "\n",
        "dat = dat.assign(earring = dat[' accessories'].str.contains('Earring').astype(float).to_list())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "D8DLweaseI_3"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "else :\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "n = finalArray.shape[0]\n",
        "trainFraction = .75\n",
        "sample = np.random.uniform(size = n) < trainFraction\n",
        "x_train = finalArray[ sample, :, :, :] / 255\n",
        "x_test =  finalArray[~sample, :, :, :] / 255\n",
        "    \n",
        "y_train = dat.earring[sample].to_numpy()\n",
        "y_test =  dat.earring[~sample].to_numpy()\n",
        "## Need to have the extra dimension\n",
        "y_train = y_train.reshape(y_train.shape[0], 1)\n",
        "y_test = y_test.reshape(y_test.shape[0], 1)\n",
        "\n",
        "y_train = torch.Tensor(y_train).to(device)\n",
        "x_train = torch.Tensor(x_train).to(device)\n",
        "trainDataset = TensorDataset(torch.Tensor(x_train), torch.Tensor(y_train))\n",
        "trainloader = torch.utils.data.DataLoader(trainDataset, batch_size = 100, shuffle = False, num_workers = 1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XKhMUCj0eI_4"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 3 * 3, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = torch.sigmoid(self.fc3(x))\n",
        "        return x\n",
        "net = Net().to(device)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HyOgp5IAeJAC"
      },
      "outputs": [],
      "source": [
        "for epoch in range(100):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pb5dvdIrn1kY"
      },
      "source": [
        "Here's the subject with the highest probability of having an earring. Let's save that subject and see what the algorithm finds so compelling about this subject."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "zm7wnvF5eUeJ",
        "outputId": "29d48d8e-f180-4334-c2fc-c46bc6898004"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([], [])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "yhat = outputs.to( torch.device(\"cpu\") ).detach().numpy()\n",
        "## Grab the image that most likely has an earring\n",
        "idx = np.argmax(yhat)\n",
        "image = inputs.to( torch.device(\"cpu\")).detach().numpy()[idx, :, :, :]\n",
        "plt.imshow( np.transpose(image , (1, 2, 0)) )\n",
        "plt.xticks([])\n",
        "plt.yticks([])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8S-JLP3oAID"
      },
      "source": [
        "Let's take the image and, one pixel at a time, zero it out. Then that pixel's won't propigate through the network. Let's then take that image and feed it through the network. If that pixel was very important, then the prediction would drop. If it wasn't very important, the prediction would stay the same. \n",
        "\n",
        "To elaborate, let $I1$ be the one with the highest probability of having an earring. Then set $I2 = I1$ except $I2[i,j] = 0$ for some fixed $i$ and $j$. Let $P$ be an array of the same size and set $P[i,j] = \\phi(I2)$ where $\\phi$ is our convolutional network. Pixels where $P$ is low means the prediction dropped after the removal of that pixel.\n",
        "\n",
        "Let's try this out on this subject."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "3AsZ9mW1fe4f",
        "outputId": "8847aa22-c8a7-4323-a4ea-4a8460085f46"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "xdim = image.shape[1]\n",
        "ydim = image.shape[2]\n",
        "probmap = np.empty([xdim, ydim])\n",
        "net.to(torch.device(\"cpu\"))\n",
        "for i in range(xdim):\n",
        "  for j in range(ydim):\n",
        "    temp = image.copy()\n",
        "    temp[0, i, j] = 0\n",
        "    temp[1, i, j] = 0\n",
        "    temp[2, i, j] = 0\n",
        "    ## add an extra row\n",
        "    temp = temp[np.newaxis, :, :, :]\n",
        "    probmap[i,j] = net(torch.tensor(temp))\n",
        "probmap.shape\n",
        "plt.imshow( probmap );\n",
        "plt.xticks([]);\n",
        "plt.yticks([]);\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SA95SRNpWku"
      },
      "source": [
        "Notice that the probability that this subject has an earing plummets when we remove the pixel exactly where the earring is at.  This is a good sign that our algorithm is doing something appropriate."
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "convolutions.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ds4bio_new",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
