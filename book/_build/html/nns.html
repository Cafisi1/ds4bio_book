
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Neural networks &#8212; Data science and AI for Bio/medical applications using python</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Pytorch by example" href="pytorch_regression.html" />
    <link rel="prev" title="Regression and FFTs" href="linearModels_FFTs.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/dasl.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Data science and AI for Bio/medical applications using python</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   Welcome!
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="git.html">
   Git, github
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ds_python.html">
   Python background
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="basic_python.html">
   Python basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="python_programming.html">
   Python programming
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="functions.html">
   Functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="python_practice.html">
   Python in practice
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="virtual_environments.html">
   Virtual Environments
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="data_cleaning.html">
   Data cleaning by example
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="EDA.html">
   Exploratory data analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="sqlite.html">
   SQL via sqlite
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="pysqlite.html">
   sqlite in python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="rBasic.html">
   Base R
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="rTidyverse.html">
   R tidyverse quick example
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="rFromPython.html">
   R from python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="pythonFromR.html">
   Python from R
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="html.html">
   HTML, CSS and javascript
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="interactive.html">
   Interactive graphics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="webscraping.html">
   Webscraping
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="dash.html">
   Dash
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="binary_classification.html">
   Introduction to binary classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="regression_through_the_origin.html">
   Regression through the origin
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="regression.html">
   Continuous prediction with regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="logistic.html">
   Logistic regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ml.html">
   Maximum Likelihood
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linearSeparable.html">
   Linear separable models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linearSeparableSMF.html">
   Interpretation of linear regression coefficients.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="regression_examples.html">
   Linear models: a classic example
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="regression_interpretation.html">
   Regression interpretation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="dft.html">
   DFT
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linearModels_FFTs.html">
   Regression and FFTs
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Neural networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="pytorch_regression.html">
   Pytorch by example
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="basic_regression_pytorch.html">
   Basic regression in pytorch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="logistic_regression_pytorch.html">
   Logistic regression in pytorch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="convnet_classifier_pytorch.html">
   Convnet classifier example
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="convolutions.html">
   Convolutions
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/nns.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/smart-stats/ds4bio_book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/smart-stats/ds4bio_book/issues/new?title=Issue%20on%20page%20%2Fnns.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/smart-stats/ds4bio_book/master?urlpath=tree/nns.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#basics">
   Basics
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#more-layers">
   More layers
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#activation-functions">
   Activation functions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#optimization">
   Optimization
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <p><a href="https://colab.research.google.com/github/smart-stats/ds4bio_book/blob/main/book/nns.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a> <a class="reference external" href="https://mybinder.org/v2/gh/smart-stats/ds4bio_book/HEAD"><img alt="Binder" src="https://mybinder.org/badge_logo.svg" /></a></p>
<div class="tex2jax_ignore mathjax_ignore section" id="neural-networks">
<h1>Neural networks<a class="headerlink" href="#neural-networks" title="Permalink to this headline">¶</a></h1>
<div class="section" id="basics">
<h2>Basics<a class="headerlink" href="#basics" title="Permalink to this headline">¶</a></h2>
<p>Let’s start by relating neural networks to regression. Consider a simple case where we have two nodes, <span class="math notranslate nohighlight">\(1\)</span> and <span class="math notranslate nohighlight">\(X\)</span> pointing to an outcome <span class="math notranslate nohighlight">\(Y\)</span>. What does this mean? Let’s first put some context around the problem. Imagine that we want to use a subject’s BMI <span class="math notranslate nohighlight">\(X\)</span> to predict their blood pressure, <span class="math notranslate nohighlight">\(Y\)</span>. This diagram represents that.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">sklearn</span> <span class="k">as</span> <span class="nn">skl</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="c1">#G = nx.Graph()</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">DiGraph</span><span class="p">()</span>

<span class="n">G</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;1&quot;</span><span class="p">,</span> <span class="n">pos</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="n">pos</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="n">pos</span> <span class="o">=</span> <span class="p">(</span><span class="mf">.5</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;1&quot;</span><span class="p">,</span> <span class="s2">&quot;Y&quot;</span><span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;Y&quot;</span><span class="p">)</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> 
        <span class="n">nx</span><span class="o">.</span><span class="n">get_node_attributes</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="s1">&#39;pos&#39;</span><span class="p">),</span> 
        <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
        <span class="n">font_weight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span> 
        <span class="n">node_size</span> <span class="o">=</span> <span class="mi">2000</span><span class="p">,</span>
        <span class="n">node_color</span> <span class="o">=</span> <span class="s2">&quot;lightblue&quot;</span><span class="p">,</span>
        <span class="n">linewidths</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">ax</span><span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">collections</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_edgecolor</span><span class="p">(</span><span class="s2">&quot;#000000&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">.3</span><span class="p">,</span> <span class="mf">1.3</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">.3</span><span class="p">,</span> <span class="mf">1.3</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_build/jupyter_execute/nns_1_0.png" src="_build/jupyter_execute/nns_1_0.png" />
</div>
</div>
<p>To interpret this diagram as a neural network, consider the following rule:</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Parent nodes that point to a child node are multiplied by weights then added together then operated on by an activation function to form the child node.</p>
</div>
<p>If the parent nodes point to the outcome, then the nodes are combined the operated on by a known function, called the <strong>activation function</strong> to form a prediction. So, in this case, this is saying that the intercept (node labeled <span class="math notranslate nohighlight">\(1\)</span>)times a weight plus BMI (node labeled <span class="math notranslate nohighlight">\(X\)</span>) times a different weight get combined to form a prediction for SBP <span class="math notranslate nohighlight">\(Y\)</span>. Or, in other words</p>
<div class="math notranslate nohighlight">
\[
\hat Y = g(w_0 \times 1 + w_1 \times X)
\]</div>
<p>where <span class="math notranslate nohighlight">\(g\)</span> is a function that we specify. So in this case, if <span class="math notranslate nohighlight">\(w_0 = 120\)</span>, <span class="math notranslate nohighlight">\(w_1 = .1\)</span> and <span class="math notranslate nohighlight">\(g\)</span> is an idenity function, <span class="math notranslate nohighlight">\(g(a) = a\)</span>, and a subject had a BMI of 30, then the prediction would be</p>
<div class="math notranslate nohighlight">
\[
\hat Y = g(120 + .1 * 30) = 120.3
\]</div>
<p>Note <span class="math notranslate nohighlight">\(g\)</span> is not shown in the diagram (though maybe you could with the shape of the child node) or something like that0. Also not shown in the daigram is:</p>
<ul class="simple">
<li><p>The loss function, i.e. how to measure the different between <span class="math notranslate nohighlight">\(\hat Y\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>.</p></li>
<li><p>The way the loss function combines subjects; we have multiple BMIs and SBPs</p></li>
<li><p>How we obtain the weights, <span class="math notranslate nohighlight">\(W_0\)</span> and <span class="math notranslate nohighlight">\(W_1\)</span>; this is done by minmizing the loss function using an algorithm</p></li>
</ul>
<p>So, imagine the case where <span class="math notranslate nohighlight">\(g\)</span> is an identity function, our loss function for different subjects is squared error and we combine different losses by adding them up. Then, our weights are obtained by minmizing</p>
<div class="math notranslate nohighlight">
\[
\sum_{i=1}^N (Y_i - \hat Y_i)^2 
\]</div>
<p>and so, presuming our optimization algorithm works well, it should be idential to linear regression.</p>
<p>Consider a different setting. Imagine if our <span class="math notranslate nohighlight">\(Y\)</span> is 0 or 1 based on whether or not the subject is taking anti-hypertensive mediations. Further, let <span class="math notranslate nohighlight">\(g\)</span> be the sigmoid function, <span class="math notranslate nohighlight">\(g(a) = 1 / \{1 + \exp(-a)\}\)</span>. Our prediction is</p>
<div class="math notranslate nohighlight">
\[
\hat Y = \{1 + \exp(-W_0 - W_1 X)\}^{-1}
\]</div>
<p>which is the logistic regression prediction with intercept <span class="math notranslate nohighlight">\(W_0\)</span> and slope <span class="math notranslate nohighlight">\(W_1\)</span>. Consider a case where
<span class="math notranslate nohighlight">\(W_0 = -4\)</span>, <span class="math notranslate nohighlight">\(W_1 = .1\)</span> and <span class="math notranslate nohighlight">\(X=30\)</span>, then our <span class="math notranslate nohighlight">\(\hat Y = 1 / \{1 + \exp[-(-4 + .1\times 30)\}]\approx .27\)</span>. Thus, this model estimates a 27% probability that a subject with a BMI of 30 has hypertension.</p>
<p>Further, if we specify that the loss function is binary cross entropy</p>
<div class="math notranslate nohighlight">
\[
- \sum_{i=1}^n \{ Y_i \log(\hat Y_i) + (1 - Y_i) \log(1 - \hat Y_i)\} / N
\]</div>
<p>then minmizing our loss function is identical to maximizing the likelihood for logistic regression.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span> <span class="o">+</span> <span class="mf">.1</span> <span class="o">*</span> <span class="mi">30</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.2689414213699951
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="more-layers">
<h2>More layers<a class="headerlink" href="#more-layers" title="Permalink to this headline">¶</a></h2>
<p>Of course, there’d be no point in using NNs for problems that we can just solve with generalized linear models. NNs get better when we add more layers, since then they can discover interactions and non-linearities. Consider the following model. Notice we quit explicitly adding the bias (intercept) term / node. In general assume the bias term is included unless otherwise specified.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#plt.figure(figsize=[2, 2])</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">DiGraph</span><span class="p">()</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;X1&quot;</span><span class="p">,</span>  <span class="n">pos</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;X2&quot;</span><span class="p">,</span>  <span class="n">pos</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;H11&quot;</span><span class="p">,</span> <span class="n">pos</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;H12&quot;</span><span class="p">,</span> <span class="n">pos</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;H21&quot;</span><span class="p">,</span> <span class="n">pos</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;H22&quot;</span><span class="p">,</span> <span class="n">pos</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="n">pos</span> <span class="o">=</span> <span class="p">(</span><span class="mf">.5</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edges_from</span><span class="p">([</span> <span class="p">(</span><span class="s2">&quot;X1&quot;</span><span class="p">,</span> <span class="s2">&quot;H11&quot;</span><span class="p">),</span>  <span class="p">(</span><span class="s2">&quot;X1&quot;</span><span class="p">,</span> <span class="s2">&quot;H12&quot;</span><span class="p">),</span>  <span class="p">(</span><span class="s2">&quot;X2&quot;</span><span class="p">,</span> <span class="s2">&quot;H11&quot;</span><span class="p">),</span>  <span class="p">(</span><span class="s2">&quot;X2&quot;</span><span class="p">,</span> <span class="s2">&quot;H12&quot;</span><span class="p">)])</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edges_from</span><span class="p">([(</span><span class="s2">&quot;H11&quot;</span><span class="p">,</span> <span class="s2">&quot;H21&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;H11&quot;</span><span class="p">,</span> <span class="s2">&quot;H22&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;H12&quot;</span><span class="p">,</span> <span class="s2">&quot;H21&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;H12&quot;</span><span class="p">,</span> <span class="s2">&quot;H22&quot;</span><span class="p">)])</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edges_from</span><span class="p">([(</span><span class="s2">&quot;H21&quot;</span><span class="p">,</span> <span class="s2">&quot;Y&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;H22&quot;</span><span class="p">,</span> <span class="s2">&quot;Y&quot;</span><span class="p">)])</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> 
        <span class="n">nx</span><span class="o">.</span><span class="n">get_node_attributes</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="s1">&#39;pos&#39;</span><span class="p">),</span> 
        <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
        <span class="n">font_weight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span> 
        <span class="n">node_size</span> <span class="o">=</span> <span class="mi">2000</span><span class="p">,</span>
        <span class="n">node_color</span> <span class="o">=</span> <span class="s2">&quot;lightblue&quot;</span><span class="p">,</span>
        <span class="n">linewidths</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">ax</span><span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">collections</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_edgecolor</span><span class="p">(</span><span class="s2">&quot;#000000&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">.3</span><span class="p">,</span> <span class="mf">3.3</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">.3</span><span class="p">,</span> <span class="mf">3.3</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_build/jupyter_execute/nns_5_0.png" src="_build/jupyter_execute/nns_5_0.png" />
</div>
</div>
<p>Usually, the nodes are added in so called layers. <span class="math notranslate nohighlight">\((X_1, X_2)\)</span> is the input layer, <span class="math notranslate nohighlight">\((H_{11}, H_{12})\)</span> is the first hidden layer, <span class="math notranslate nohighlight">\((H_{21}, H_{22})\)</span> is the second hidden layer and <span class="math notranslate nohighlight">\(Y\)</span> is the output layer. Imagine plugging an <span class="math notranslate nohighlight">\(X_1\)</span> and <span class="math notranslate nohighlight">\(X_2\)</span> into this network. It would feed forward through the network as</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
H_{11} = &amp; g_1(W_{011} + W_{111} X_1 + W_{211} X_2) \\
H_{12} = &amp; g_1(W_{012} + W_{112} X_1 + W_{212} X_2) \\
H_{21} = &amp; g_2(W_{021} + W_{121} H_{11} + W_{221} H_{12}) \\
H_{22} = &amp; g_2(W_{022} + W_{122} H_{12} + W_{222} H_{12}) \\
\hat Y = &amp; g_3(W_{031} + W_{131} H_{21} + W_{231} H_{22})
\end{align}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(g_k\)</span> are specified activation functions. Typically, we would have a different activation function for the output layer than the others, and the other would have the same activation function. So, for example, if <span class="math notranslate nohighlight">\(Y\)</span> was binary, like hypertension diagnosis, then <span class="math notranslate nohighlight">\(g_1=g_2\)</span> and <span class="math notranslate nohighlight">\(g_3\)</span> would be a sigmoid.</p>
</div>
<div class="section" id="activation-functions">
<h2>Activation functions<a class="headerlink" href="#activation-functions" title="Permalink to this headline">¶</a></h2>
<p>The output activation function tends to be based on the structure of the outcome. For example, a binary outcome would likely have a sigmoidal, or other function from <span class="math notranslate nohighlight">\(\mathbb{R}\)</span> to <span class="math notranslate nohighlight">\([0, 1]\)</span> so as to model a probability. Historically, the internal activation functions were binary thresholds. This was owning to the fact that neural networks were models of (biological) neurons and the threshold was a model of an action potential being propigated. However, modern neural networks have less of a direct connection to their biological motivation and other activation functions tend to be used. The most popular right now is the rectified linear unit (RELU) function. This is simply:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
RELU(a) = \left\{
\begin{array}{ll}
a &amp; \text{if $a&gt;0$} \\
0 &amp; \text{otherwise}
\end{array}
\right.
= a \times I(a &gt; 0)
\end{split}\]</div>
<p>Plotted, this is:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="mi">4</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_build/jupyter_execute/nns_8_0.png" src="_build/jupyter_execute/nns_8_0.png" />
</div>
</div>
<p>If a bias term is included, then the fact that the RELU is centered at zero isn’t important, since the intercept term effectively shifts the function around. These kinds of splin terms are incredibly flexible. Just to show you an example, let’s fit the sine function using a collection of shifted RELUs. This is just</p>
<div class="math notranslate nohighlight">
\[
Y = \sin(X) + \epsilon
\]</div>
<p>being fit with</p>
<div class="math notranslate nohighlight">
\[
\sum_{i=1}^N \left\{ Y_i - W_{021} - \sum_{j=1}^{d} W_{j21} g(W_{0j1} + W_{1j1} X_i) \right\}^2
\]</div>
<p>where the <span class="math notranslate nohighlight">\(W_{kj}\)</span> are the weights for layer <span class="math notranslate nohighlight">\(k\)</span>. Below, we’re just setting <span class="math notranslate nohighlight">\(W_{1j1} = 1\)</span> and specifying the <span class="math notranslate nohighlight">\(W_{0j1}\)</span> at a sequence of values.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>## Generate some data, a sine function on 0,4*pi
n = 1000
x = np.linspace(0, 4 * np.pi, n)
y = np.sin(x) + .2 * np.random.normal(size = n)

## Generate the spline regressors
df = 30
knots = np.linspace(x.min(), x.max(), df)
xmat = np.zeros((n, d))
for i in range(0, d): xmat[:,i] = x$ * (x &gt; knots[i])

## Fit them
from sklearn.linear_model import LinearRegression
yhat = LinearRegression().fit(xmat, y).predict(xmat)

## Plot them versus the data
plt.plot(x, y);
plt.plot(x, yhat);
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_build/jupyter_execute/nns_10_0.png" src="_build/jupyter_execute/nns_10_0.png" />
</div>
</div>
<p>This corresponds to a network like depicted below if there were <span class="math notranslate nohighlight">\(d=3\)</span>  hidden nodes, there was a relu activation function at the first layer, then a identity activation function for the output layer and the weights for the first layer are specified.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">DiGraph</span><span class="p">()</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">,</span>  <span class="n">pos</span> <span class="o">=</span>  <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;H11&quot;</span><span class="p">,</span> <span class="n">pos</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;H12&quot;</span><span class="p">,</span> <span class="n">pos</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;H13&quot;</span><span class="p">,</span> <span class="n">pos</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="n">pos</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edges_from</span><span class="p">([(</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;H11&quot;</span><span class="p">),</span>  <span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;H12&quot;</span><span class="p">),</span>  <span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;H13&quot;</span><span class="p">)])</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edges_from</span><span class="p">([(</span><span class="s2">&quot;H11&quot;</span><span class="p">,</span> <span class="s2">&quot;Y&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;H12&quot;</span><span class="p">,</span> <span class="s2">&quot;Y&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;H13&quot;</span><span class="p">,</span> <span class="s2">&quot;Y&quot;</span><span class="p">)])</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> 
        <span class="n">nx</span><span class="o">.</span><span class="n">get_node_attributes</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="s1">&#39;pos&#39;</span><span class="p">),</span> 
        <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
        <span class="n">font_weight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span> 
        <span class="n">node_size</span> <span class="o">=</span> <span class="mi">2000</span><span class="p">,</span>
        <span class="n">node_color</span> <span class="o">=</span> <span class="s2">&quot;lightblue&quot;</span><span class="p">,</span>
        <span class="n">linewidths</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">ax</span><span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">collections</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_edgecolor</span><span class="p">(</span><span class="s2">&quot;#000000&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">.3</span><span class="p">,</span> <span class="mf">3.3</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">.3</span><span class="p">,</span> <span class="mf">3.3</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_build/jupyter_execute/nns_12_0.png" src="_build/jupyter_execute/nns_12_0.png" />
</div>
</div>
<p>We can actually fit this function way better using splines and a little bit more care. However, this helps show how even one layer of RELU activated nodes can start to fit complex shapes.</p>
</div>
<div class="section" id="optimization">
<h2>Optimization<a class="headerlink" href="#optimization" title="Permalink to this headline">¶</a></h2>
<p>One of the last bits of the puzzle we have to figure out is how to obtain the weights. A good strategy would be to minimize the loss function. However, it’s hard to minmize. If we had a derivative, we could try the following. Let <span class="math notranslate nohighlight">\(L(W)\)</span> be the loss function for weights <span class="math notranslate nohighlight">\(W\)</span>. Note, we’re omitting the fact that this is a function of the data (predictors and outcome) as well, since that’s a set of fixed numbers. Consider updating parameters as</p>
<div class="math notranslate nohighlight">
\[
W^{(new)} = W^{(old}) - e * L'(W^{(old)})
\]</div>
<p>What does this do? It moves the parameters by a small amount, <span class="math notranslate nohighlight">\(e\)</span>, called the <strong>learning rate</strong>, in the direction the opposite of the gradient. Think of a one dimensional convex function. If the derivative at a point is positive, then that point is larger than where the minimum is. Similarily, if the derivative is negative, it’s smaller. So, the idea is to head a small amount in the opposite direction of the derivative. How much? How about along the line of the derivative? That’s all gradient descent does, just in more than one dimension.</p>
<p>How do we get the gradient? Consider the following. If <span class="math notranslate nohighlight">\(X\)</span> is our vector of predictors and <span class="math notranslate nohighlight">\(Y\)</span> is our vector of outputs, a neural network with 3 layers, can be thought of as, where <span class="math notranslate nohighlight">\(L_k\)</span> is layer <span class="math notranslate nohighlight">\(K\)</span> and <span class="math notranslate nohighlight">\(W_k\)</span> are the weights for that layer:</p>
<div class="math notranslate nohighlight">
\[
L_3(L_2(L_1(X, W_1), W_2) W_3)
\]</div>
<p>Or a series of function compositions. Recall from calculus, if we want the derivative of composed functions we have a really simple rule called the chain rule:</p>
<div class="math notranslate nohighlight">
\[
\frac{d}{dx}f(g(x)) = f'(g(x)) g'(x)
\]</div>
<p>I.e. if <span class="math notranslate nohighlight">\(h=f(u)\)</span> and <span class="math notranslate nohighlight">\(u = g(x)\)</span> then <span class="math notranslate nohighlight">\(\frac{dh}{dx} = \frac{dh}{du}\frac{du}{dx}\)</span>. Thus, characterized this way, the chain rule formally acts like fractions (though this is a symbolic equivalence having entirely different underlying meanings).</p>
<p>If we use the chain rule on our composed loss functions, we wind up bookkeeping backwards through our neural network. That is why it’s called backwards propagation (backprop).</p>
<p>So, our algorithm goes something like this.
Given, <span class="math notranslate nohighlight">\(W^{(new)}\)</span>, network, <span class="math notranslate nohighlight">\(\phi(X, W)\)</span>, which depends on the predictors and the weights
and loss, <span class="math notranslate nohighlight">\(L(Y, \hat Y)\)</span>, which depends on the observed and predicted outputs.</p>
<ol class="simple">
<li><p>Set <span class="math notranslate nohighlight">\(W^{(old)}=W^{(new)}\)</span></p></li>
<li><p>Calculate <span class="math notranslate nohighlight">\(\hat Y = \phi(X, W^{(old)})\)</span> and loss <span class="math notranslate nohighlight">\(L(Y, \hat Y)\)</span>.</p></li>
<li><p>Use back propagation to get to get a numerical approximation to <span class="math notranslate nohighlight">\(\frac{d}{dW} L\{Y, \phi(X, W)\} |_{W=W^{(old)}} = L'(W^{(old)})\)</span></p></li>
<li><p>Update <span class="math notranslate nohighlight">\(W^{(new)} = W^{(old)} - e L'(W^{(old)})\)</span></p></li>
<li><p>Go to step 0.</p></li>
</ol>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="linearModels_FFTs.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title">Regression and FFTs</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="pytorch_regression.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title">Pytorch by example</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Brian Caffo<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>