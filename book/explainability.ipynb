{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/smart-stats/ds4bio_book/blob/main/book/explainability.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/smart-stats/ds4bio_book/HEAD)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://raw.githubusercontent.com/cryptopunksnotdead/punks.attributes/master/original/0-999.csv\n",
      "https://raw.githubusercontent.com/cryptopunksnotdead/punks.attributes/master/original/1000-1999.csv\n",
      "https://raw.githubusercontent.com/cryptopunksnotdead/punks.attributes/master/original/2000-2999.csv\n",
      "https://raw.githubusercontent.com/cryptopunksnotdead/punks.attributes/master/original/3000-3999.csv\n",
      "https://raw.githubusercontent.com/cryptopunksnotdead/punks.attributes/master/original/4000-4999.csv\n",
      "https://raw.githubusercontent.com/cryptopunksnotdead/punks.attributes/master/original/5000-5999.csv\n",
      "https://raw.githubusercontent.com/cryptopunksnotdead/punks.attributes/master/original/6000-6999.csv\n",
      "https://raw.githubusercontent.com/cryptopunksnotdead/punks.attributes/master/original/7000-7999.csv\n",
      "https://raw.githubusercontent.com/cryptopunksnotdead/punks.attributes/master/original/8000-8999.csv\n",
      "https://raw.githubusercontent.com/cryptopunksnotdead/punks.attributes/master/original/9000-9999.csv\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "imgURL = \"https://raw.githubusercontent.com/larvalabs/cryptopunks/master/punks.png\"\n",
    "urllib.request.urlretrieve(imgURL, \"cryptoPunksAll.jpg\")\n",
    "img = PIL.Image.open(\"cryptoPunksAll.jpg\").convert(\"RGB\")\n",
    "imgArray = np.asarray(img)\n",
    "\n",
    "finalArray = np.empty((10000, 3, 24, 24))\n",
    "for i in range(100):\n",
    "  for j in range(100):\n",
    "    a, b = 24 * i, 24 * (i + 1)  \n",
    "    c, d = 24 * j, 24 * (j + 1) \n",
    "    idx = j + i * (100)\n",
    "    finalArray[idx,0,:,:] = imgArray[a:b,c:d,0]\n",
    "    finalArray[idx,1,:,:] = imgArray[a:b,c:d,1]\n",
    "    finalArray[idx,2,:,:] = imgArray[a:b,c:d,2]\n",
    "\n",
    "baseUrl = \"https://raw.githubusercontent.com/cryptopunksnotdead/punks.attributes/master/original/\"\n",
    "for i in range(0,10000, 1000):\n",
    "  url = baseUrl+str(i)+\"-\"+str(i + 999)+\".csv\"\n",
    "  print(url)\n",
    "  if (i == 0):\n",
    "    dat = pd.read_csv(url)\n",
    "  else :\n",
    "    dat = pd.concat ([dat, pd.read_csv(url)], \n",
    "                      join = 'inner',\n",
    "                     ignore_index = True)\n",
    "    \n",
    "\n",
    "dat = dat.assign(earring = dat[' accessories'].str.contains('Earring').astype(float).to_list())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else :\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "n = finalArray.shape[0]\n",
    "trainFraction = .75\n",
    "sample = np.random.uniform(size = n) < trainFraction\n",
    "x_train = finalArray[ sample, :, :, :] / 255\n",
    "x_test =  finalArray[~sample, :, :, :] / 255\n",
    "    \n",
    "y_train = dat.earring[sample].to_numpy()\n",
    "y_test =  dat.earring[~sample].to_numpy()\n",
    "## Need to have the extra dimension\n",
    "y_train = y_train.reshape(y_train.shape[0], 1)\n",
    "y_test = y_test.reshape(y_test.shape[0], 1)\n",
    "\n",
    "y_train = torch.Tensor(y_train).to(device)\n",
    "x_train = torch.Tensor(x_train).to(device)\n",
    "trainDataset = TensorDataset(torch.Tensor(x_train), torch.Tensor(y_train))\n",
    "trainloader = torch.utils.data.DataLoader(trainDataset, batch_size = 100, shuffle = False, num_workers = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 3 * 3, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "net = Net().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(100):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "convolutions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:.conda-ds4bio]",
   "language": "python",
   "name": "conda-env-.conda-ds4bio-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
