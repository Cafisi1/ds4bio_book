{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ad7348d2-466b-45fa-9096-0b052f42b5b5",
      "metadata": {
        "id": "ad7348d2-466b-45fa-9096-0b052f42b5b5"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smart-stats/ds4bio_book/blob/main/book/gpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/smart-stats/ds4bio_book/HEAD)\n",
        "\n",
        "# Parallelism and GPU computing\n",
        "\n",
        "AI calculations involve quite a few arithmetic calculations. Graphics processing units (GPUs) are computer chips that were designed to parallelize large numbers of small arithmetic calculations. They were designed as such because computer graphics involve rotations, shifts, scaling, etc. of images, are a matrix manipulations. \n",
        "\n",
        "Currently, I don't have a GPU in my personal computer. Some options for trying out GPUs include Google Colab and Paperspace to name two examples. I'm doing this example on Colab\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c36c84d2-f951-4197-b765-42c50ae1efb9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c36c84d2-f951-4197-b765-42c50ae1efb9",
        "outputId": "12233b5d-7360-49dd-ea1b-771049220fa3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06decc32-1d48-471c-964b-c86c1b1dc558",
      "metadata": {
        "id": "06decc32-1d48-471c-964b-c86c1b1dc558"
      },
      "source": [
        "By default, calculations will be on the CPU. You have to actually migrate calculations to the GPU. Here I write the code in such a way that it works on the GPU or CPU depending on whether a GPU is available. It's typical to create a variable called \"device\" that references the GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c610caeb-4553-4dfd-85fa-e8d3585b2929",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c610caeb-4553-4dfd-85fa-e8d3585b2929",
        "outputId": "9455e88c-5b34-4e4d-ca3c-770cff970a07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "else :\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at the reduction in runtime"
      ],
      "metadata": {
        "id": "xgX82fORnt0y"
      },
      "id": "xgX82fORnt0y"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "126ca6d3-71ce-442a-a4f5-a02adcdb3a9e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "126ca6d3-71ce-442a-a4f5-a02adcdb3a9e",
        "outputId": "6bd61c71-99e4-4822-c858-4dd5b01463d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The % reduction in runtime is: [69.79166666666667]\n",
            "The % reduction in runtime is: [73.96593673965937]\n",
            "The % reduction in runtime is: [76.03406326034063]\n",
            "The % reduction in runtime is: [75.97633136094674]\n",
            "The % reduction in runtime is: [78.29638273045506]\n",
            "The % reduction in runtime is: [75.93023255813954]\n",
            "The % reduction in runtime is: [78.57974388824213]\n",
            "The % reduction in runtime is: [77.97468354430379]\n",
            "The % reduction in runtime is: [78.54588796185935]\n",
            "The % reduction in runtime is: [78.66354044548652]\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "for i in range(10):\n",
        "  test_matrix = torch.randn([100000, 10])\n",
        "  test_matrix_cuda = test_matrix.to(device)\n",
        "\n",
        "  start = time.time()\n",
        "  test_matrix.sum()\n",
        "  end = time.time()\n",
        "\n",
        "  a = end - start\n",
        "\n",
        "  start = time.time()\n",
        "  test_matrix_cuda.sum()\n",
        "  end = time.time()\n",
        "\n",
        "  b = end - start\n",
        "\n",
        "  print(\"The % reduction in runtime is: \", end = \"\")\n",
        "  print([(1 - b / a) * 100])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "import PIL\n",
        "\n",
        "## Read in and organize the data\n",
        "imgURL = \"https://raw.githubusercontent.com/larvalabs/cryptopunks/master/punks.png\"\n",
        "urllib.request.urlretrieve(imgURL, \"cryptoPunksAll.jpg\")\n",
        "img = PIL.Image.open(\"cryptoPunksAll.jpg\").convert(\"RGB\")\n",
        "imgArray = np.asarray(img)\n",
        "finalArray = np.empty((10000, 3, 24, 24))\n",
        "for i in range(100):\n",
        "  for j in range(100):\n",
        "    a, b = 24 * i, 24 * (i + 1)  \n",
        "    c, d = 24 * j, 24 * (j + 1) \n",
        "    idx = j + i * (100)\n",
        "    finalArray[idx,0,:,:] = imgArray[a:b,c:d,0]\n",
        "    finalArray[idx,1,:,:] = imgArray[a:b,c:d,1]\n",
        "    finalArray[idx,2,:,:] = imgArray[a:b,c:d,2]\n",
        "\n",
        "n = finalArray.shape[0]\n",
        "x_real = finalArray / 255\n",
        "x_real = torch.tensor(x_real.astype(np.float32))\n",
        "kernel_size = 5\n",
        "generator_input_dim = [16, 3, 3]\n",
        "\n",
        "class create_generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()        \n",
        "        self.net = nn.Sequential(\n",
        "            nn.ConvTranspose2d(16, 128, 10, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(128, 3, 4, 2, 1, bias=False), \n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        " \n",
        "## Use the discriminator from the convnet chapter\n",
        "class create_discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 12, 5)\n",
        "        self.fc1 = nn.Linear(12 * 3 * 3, 32)\n",
        "        self.fc2 = nn.Linear(32, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        return x\n",
        "    \n",
        "        \n",
        "generator = create_generator()\n",
        "discriminator = create_discriminator()\n",
        "\n",
        "lr = 1e-4\n",
        "\n",
        "## y is n real images then n fake images\n",
        "y = torch.concat( (torch.ones(n), torch.zeros(n) ) ) \n",
        "\n",
        "## Set up optimizers\n",
        "optimizerD = optim.Adam(discriminator.parameters(), lr=lr)\n",
        "optimizerG = optim.Adam(generator.parameters(), lr=lr)\n",
        "\n",
        "## Set up the loss function\n",
        "loss_function = nn.BCELoss()"
      ],
      "metadata": {
        "id": "4tV0_A_Zhnn6"
      },
      "id": "4tV0_A_Zhnn6",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "randomBatchSize = .1\n",
        "n_epochs = 20\n",
        "trainFraction = .1\n",
        "\n",
        "for epoch in range(n_epochs):          \n",
        "    ## Generate the batch sample\n",
        "    sample = np.random.uniform(size = n) < trainFraction\n",
        "    n_batch = np.sum(sample)\n",
        "\n",
        "    ## Generate the simulated embedding    \n",
        "    embedding = torch.randn([n_batch]+generator_input_dim, device = device)\n",
        "    \n",
        "    \n",
        "    ## Generate new fake images\n",
        "    x_fake = generator(embedding)\n",
        "    \n",
        "    ## train the discriminator\n",
        "    ## zero out the gradient\n",
        "    discriminator.zero_grad()\n",
        "\n",
        "    ## run the generated and fake images through the discriminator\n",
        "    yhat_fake = discriminator(x_fake.detach())\n",
        "    yhat_real = discriminator(x_real[sample,:, :, :])\n",
        "    ## Note you have to concatenate them in the same order as \n",
        "    ## the previous cell. Remember we did real then fake\n",
        "    yhat = torch.concat( (yhat_real, yhat_fake) ).reshape(-1)\n",
        "\n",
        "    ## Calculate loss on all-real batch \n",
        "    y = torch.concat( (torch.ones(n_batch), torch.zeros(n_batch) ) ) \n",
        "\n",
        "    discriminator_error = loss_function(yhat, y)\n",
        "\n",
        "    # Calculate gradients for D in backward pass\n",
        "    discriminator_error.backward(retain_graph = True)\n",
        "\n",
        "    # Update the discriminator\n",
        "    optimizerD.step()\n",
        "\n",
        "    ## Train the generator\n",
        "    ## zero out the gradient\n",
        "    generator.zero_grad()\n",
        "    ## The discriminator has been udpated, so push the data through the \n",
        "    ## new discriminator\n",
        "    yhat_fake = discriminator(x_fake)\n",
        "    ## Note the outcome for the generator is all ones even\n",
        "    ## though we're classifying real as 1 and fake as 0\n",
        "    ## In other words, we want the loss for the generator to be\n",
        "    ## based on how real-like the generated data is\n",
        "    generator_error = loss_function( yhat_fake,  torch.ones( (n_batch, 1) ) )\n",
        "    ## Calculate the backwards error\n",
        "    generator_error.backward(retain_graph = False)\n",
        "    # Update the discriminator\n",
        "    optimizerG.step()\n",
        "    \n",
        "    if (epoch + 1) % 10 == 0:  \n",
        "      print(epoch, end = \",\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "CPvuMtxZjZVU",
        "outputId": "ee275ee0-1fa4-41ca-a02d-1932a49402a8"
      },
      "id": "CPvuMtxZjZVU",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-ff23fdc27666>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m## Generate new fake images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mx_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m## train the discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-0a030a2601a3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     40\u001b[0m         )\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m## Use the discriminator from the convnet chapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    925\u001b[0m         return F.conv_transpose2d(\n\u001b[1;32m    926\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m             output_padding, self.groups, self.dilation)\n\u001b[0m\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "name": "gpu.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}